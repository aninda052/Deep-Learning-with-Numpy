{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural networks\n",
    "\n",
    "Recurrent Neural Networks (RNN) are very effective for sequence tasks because they have \"memory\" .They are able to this by defining a recurrence relation over timesteps which is typically the following formula -\n",
    "\n",
    "$$ S_k =f(S_{k-1}â‹…W_{rec} +X_k . W_x)$$\n",
    "\n",
    "\n",
    "Where $S_k$ is the state at time $k$, $X_k$ an input at time $k$, $W_{rec}$ and $W_x$ are parameters like the weights parameters in feedforward nets ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN cell\n",
    " \n",
    "Recurrent neural network can be seen as the repetition of a single cell . First we are going to implement a single cell  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleCellForword(currentStateInput,currentLayerWeight, previoustState, previousLayerWeight):\n",
    "\n",
    "    currentStat= np.dot(previousLayerWeight, previoustState) + np.dot(currentLayerWeight, currentStateInput) \n",
    "    \n",
    "    return currentStat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Forward Pass\n",
    "\n",
    "We can see an RNN as the repetition of the cell we've just built . If our input sequence of data is carried over 5 time steps, then we will copy the RNN cell 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwordPass(input_,currentLayerWeight,previousLayerWeight) :\n",
    "    \n",
    "    for currentStateInput in input_ :\n",
    "        currentState = singleCellForword(currentStateInput,currentLayerWeight, previoustState, previousLayerWeight)\n",
    "        previoustStat = currentStat\n",
    "    \n",
    "    return currentStat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def error(actual, predict): \n",
    "#     return np.mean((actual - predict)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
